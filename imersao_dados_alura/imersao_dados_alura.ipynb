{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "imersao_dados_alura.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpU2YZT1Pb9i"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uk49oMVKusE1"
      },
      "source": [
        "\n",
        "url_dados = 'https://github.com/alura-cursos/imersaodados3/blob/main/dados/dados_experimentos.zip?raw=true'\n",
        "\n",
        "dados = pd.read_csv(url_dados, compression = 'zip')\n",
        "dados\n",
        "\n",
        "# o compression = 'zip' descompacta o documento"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtz9WiWaTJD6"
      },
      "source": [
        "dados.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqpqfSQYT4am"
      },
      "source": [
        "dados.shape\n",
        "#informação do total de linhas e colunas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VC9kDHGULHx"
      },
      "source": [
        "dados['tratamento']\n",
        "#selecionada somente a serie tratamento"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkl4TthuUa0V"
      },
      "source": [
        "dados['tratamento'].unique()\n",
        "#mostra quais são os valores unicos encontrados na tabela unica"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXZIbCRsVbjG"
      },
      "source": [
        "dados['tempo'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjJTqK-AdJJ5"
      },
      "source": [
        "dados['dose'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgytUwacdO8V"
      },
      "source": [
        "dados['droga'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRCJpT1beWFj"
      },
      "source": [
        "dados['g-0'].unique()\n",
        "\n",
        "# esses números nos dizem a expressão de cada gene frente as drogas ou a exposição."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tH2CnGg6ewxJ"
      },
      "source": [
        "dados['tratamento'].value_counts()\n",
        "\n",
        "#quantidade de valores que tem em cada um das colunas "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fe-sLmycg-wW"
      },
      "source": [
        "dados['dose'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nou5ef1Mjdn7"
      },
      "source": [
        "dados['droga'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiyCmSjdj9QF"
      },
      "source": [
        "dados['tratamento'].value_counts(normalize = True)\n",
        "\n",
        "#calcula a normalização dos dados, calculando assim a proporção entre os dados de tratamento"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2U5RXGWIkkq6"
      },
      "source": [
        "dados['dose'].value_counts(normalize = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0sKyarAksYT"
      },
      "source": [
        "dados['tratamento'].value_counts().plot.pie()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVihB3-5k5u2"
      },
      "source": [
        "dados['tempo'].value_counts().plot.pie()\n",
        "#essa forma não é muito facil de ver a diferença entre os valores, pois o balanceamento entre os valores está muito proximo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htyUseRillmK"
      },
      "source": [
        "dados['tempo'].value_counts().plot.bar()\n",
        "\n",
        "#é interessante estudar cada tipo de grafico e também as melhores situações para utilizar cada um deles"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WTfBK5Go24l"
      },
      "source": [
        "dados_filtrados = dados[dados['g-0'] > 0]\n",
        "dados_filtrados.head()\n",
        "\n",
        "#Analisa quais sao os valores de g-0 que são maiores que 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqanP_xQpjwj"
      },
      "source": [
        "dados.columns\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKzY76sdsR4G"
      },
      "source": [
        "nome_das_colunas = dados.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9R10Mwo6tp6T"
      },
      "source": [
        "novo_nome_coluna = []\n",
        "\n",
        "for coluna in nome_das_colunas:\n",
        "  coluna = coluna.replace('-', '_')\n",
        "  novo_nome_coluna.append(coluna)\n",
        "dados.columns = novo_nome_coluna \n",
        "\n",
        "dados.head()\n",
        "\n",
        "#Esse for roda todo o array e faz a substituição dos nomes das colunas, nas colunas\n",
        "#que tem o '-' ele vai substituir por '_'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiQyhx2KuPFj"
      },
      "source": [
        "dados_filtrados = dados[dados['g_0'] > 0]\n",
        "dados_filtrados.head()\n",
        "\n",
        "#comparação do resultado usando Query com o resultado usando máscara + slice"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1uzH4GiuUj_"
      },
      "source": [
        "dados_filtrados = dados.query('g_0 > 0')\n",
        "dados_filtrados.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZE-hUf2jwBSP"
      },
      "source": [
        "Deixando os graficos mais bonitin hahaha"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_S0xCwtBv7nP"
      },
      "source": [
        "valore_tempo = dados['tempo'].value_counts(ascending=True)\n",
        "valore_tempo.sort_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCeXtowpwJYS"
      },
      "source": [
        "plt.figure(figsize=(15, 10))\n",
        "valore_tempo = dados['tempo'].value_counts(ascending=True)\n",
        "ax = valore_tempo.sort_index().plot.bar()\n",
        "ax.set_title('Janelas de tempo', fontsize=20)\n",
        "ax.set_xlabel('Tempo', fontsize=18)\n",
        "ax.set_ylabel('Quantidade', fontsize=18)\n",
        "plt.xticks(rotation = 0, fontsize=16)\n",
        "plt.yticks(fontsize=16)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0q0jhY3Nzok"
      },
      "source": [
        "dados"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peT1doaixFxF"
      },
      "source": [
        "mapa = {'droga': 'composto'}\n",
        "dados.rename(columns=mapa, inplace=True)\n",
        "\n",
        "#altera o nome da coluna 'droga' por 'composto'\n",
        "#parâmetro 'inplace = True', esse parâmetro faz com que os dados sejam modificados no local e o dataframe será atualizado. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Nc-Mcuq3UZH"
      },
      "source": [
        "dados.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJB-ini22vL2"
      },
      "source": [
        "cod_compostos = dados['composto'].value_counts().index[0:5]\n",
        "#elenca os 5 compostos que mais aparecem. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehdt25yD4dO6"
      },
      "source": [
        "cod_compostos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2fNH2qnMoGu"
      },
      "source": [
        "dados.query('composto in @cod_compostos')\n",
        "#realiza um filtro em nossos dados, selecionando apenas as linhas nas quais o \n",
        "#composto esteja dentro da lista cod_composto (lista que representa os 5 compostos mais testados no experimento) \n",
        "#e utiliza o método query para resolver este problema.\n",
        "\n",
        "#Como parâmetro da função, passamos uma string contendo a lógica para realização \n",
        "#da seleção dos dados. O que queremos é o seguinte: o queryprecisa retornar para \n",
        "#nós todas as linhas contendo os 5 compostos mais utilizados. Logo, a string necessária para isso é: composto in @cod_compostos.\n",
        "\n",
        "#Usamos composto porque essa é a coluna a ser verificada no dataframe e cod_compostos \n",
        "#por ser a lista com os top 5 compostos, o detalhe aqui é que o @ é necessário para \n",
        "#informar o query que cod_composto é uma variável que já foi definida fora da função."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEnOYUSHOAX2"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.set()\n",
        "plt.figure(figsize=(8, 6))\n",
        "ax = sns.countplot(x = 'composto', data=dados.query('composto in @cod_compostos'))\n",
        "ax.set_title('Top 5 compostos')\n",
        "plt.show()\n",
        "\n",
        "#O countplot é um gráfico pré-programado da biblioteca Seaborne, por isso, precisaremos fazer a importação padrão da mesma (import seaborn as sns)\n",
        "#para que possamos enxergar o gráfico com os padrões de configuração da biblioteca, precisamos rodar sns.set()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-KIyIK9PmPw"
      },
      "source": [
        "len(dados['g_0'].unique())\n",
        "#Como temos diversos compostos únicos dentro da coluna g-0, não é viável que façamos o mesmo gráfico utilizado anteriormente. Por isso, precisamos traçar uma nova estratégia para visualizar os nossos dadose aqui, usaremos um histograma. O primeiro passo, é identificar qual o valor mínimo (min()) e o valor máximo (max()) \n",
        "#para entender qual o intervalo númerico com o qual estamos trabalhando."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYlxevUlTEjE"
      },
      "source": [
        "dados['g_0'].min()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6zwduREUe9M"
      },
      "source": [
        "dados['g_0'].max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bS9m7DK6VPcO"
      },
      "source": [
        "dados['g_0'].hist(bins = 100, figsize=(20, 6))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAxKtAlMWaGD"
      },
      "source": [
        "dados['g_19'].hist(bins = 100, figsize=(20, 6))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zd9OdSZvXJMv"
      },
      "source": [
        "dados.describe()\n",
        "#olha as descrições das estatisticas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "su5YCaymXiB7"
      },
      "source": [
        "dados.loc[:,'g_0':'g_771'].describe()\n",
        "#Como argumentos, passamos primeiramente o :, os dois pontos faz com que o loc[] retorne todos os elementos de uma \n",
        "#determinada coluna, isso é importante quando não sabemos qual a quantidade de linhas de um dataframe. E, o segundo\n",
        "# elemento, passamos as colunas que são de nosso interesse. No caso, queremos que a função nos retorne todos os elementos das colunas g-0até g-771. \n",
        "#E, por fim, podemos declarar a nossa função de interesse a partir deste filtro realizado nos dados, o describe()."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBayQLAPYPr5"
      },
      "source": [
        "dados.loc[:,'g_0':'g_771'].describe().T['mean'].hist(bins=30, figsize=(20, 6))\n",
        "\n",
        "#trasforma as linhas em colunas\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpoT_EwMaYiM"
      },
      "source": [
        "dados.loc[:,'g_0':'g_771'].describe().T['min'].hist(bins=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQ6M4vnSgFGK"
      },
      "source": [
        "dados.loc[:,'g_0':'g_771'].describe().T['max'].hist(bins=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zPa_3nKgd7r"
      },
      "source": [
        "sns.boxplot(x='g_0' , data=dados)\n",
        "#O boxplot apresenta uma caixa no meio onde podemos identificar a mediana (linha \n",
        "#no meio da caixa que é o ponto onde metade dos dados estão na direita e a outra \n",
        "#metade para a esquerda), os outliers (pontos acima ou abaixo do eixo principal do \n",
        "#gráfico que representam valores discrepantes para mais ou para menos), a maior \n",
        "#concentração dos dados (caixa principal que representa onde está a mior parte dos dados - \n",
        "#primeiro quartil (25%) e terceiro quartil (75%)) e os máximos e mínimos desconsiderando os \n",
        "#outliers (linhas laterais à caixa principal). \n",
        "#O boxplot é uma importante ferramenta na visualização de dados porque em apenas um gráfico, podemos identificar várias métricas estatísticas."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppKlWA7khyGQ"
      },
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "sns.boxplot(y='g_0', x='tratamento' , data=dados)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJiVIoWLjIAd"
      },
      "source": [
        "pd.crosstab(dados['dose'], dados['tempo'])\n",
        "#Esta função recebe como argumentos os dados que gostaríamos de correlacionar de \n",
        "#uma maneira bem simples: crosstab(dataframe['coluna1'], dataframe['coluna2']) e \n",
        "#então, como retorno, temos uma matriz que relaciona essas variáveis a partir da frequência.\n",
        "\n",
        "#Podemos ver que as categorias da variável dose transformaram-se em linhas e as categorias da variável tempo são colunas."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJzka8XgjSnN"
      },
      "source": [
        "pd.crosstab([dados['dose'], dados['tempo']],  dados['tratamento'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNILs83LlAzG"
      },
      "source": [
        "pd.crosstab([dados['dose'], dados['tempo']],  dados['tratamento'], values=dados['g_0'], aggfunc='mean')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfwtfO7plT8s"
      },
      "source": [
        "dados[['g_0', 'g_3']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NM0H90nzlfni"
      },
      "source": [
        "O scatterplot é um tipo de gráfico pré programado da biblioteca Seaborn e recebe como parâmetros a variável que vai ser usada no eixo x, a variável do eixo y e, por fim, o conjunto de dados.\n",
        "\n",
        "O código ficará:\n",
        "\n",
        "sns.scatterplot(x = 'variavel para o eixo x', y = 'variavel para o eixo y', data = base de dados)\n",
        "\n",
        "E, como queremos investigar as variáveis g-0 e g-3, atribuímos cada uma delas a um eixo.\n",
        "\n",
        "O gráfico de dispersão utiliza os dados como uma coleção de pontos cartesianos e ele é usado para apurar se há relação de causa e efeito entre duas variáveis quantitativas.\n",
        "\n",
        "No nosso caso, cada linha será um par ordenado de acordo com o que declaramos no código, ou seja, o valor de g-0 será a cordenada x e o valor de g-3 será a coordenada y.\n",
        "\n",
        "Por exemplo: para a linha 0 da base de dados teremos (1,0620 , -0,6208)\n",
        "\n",
        "Mas, por outro lado, a partir do gráfico de dispersão, não podemos dizer que uma variável afeta a outra, podemos apenas definir se há relação entre elas e qual a intensidade disso."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a19sr_SFlhm2"
      },
      "source": [
        "sns.scatterplot(x='g_0', y = 'g_3', data=dados)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgMs-By1l-AR"
      },
      "source": [
        "Observando o gráfico que construímos acima, não parecemos encontrar nenhum padrão tão definido. Então, vamos confrontar mais duas colunas para verificar se encontramos algum padrão melhor definido.\n",
        "\n",
        "Aqui, vamos usar a variável g-0 para o eixo x e a variável g-8 para o eixo y para construir o nosso novo gráfico.\n",
        "\n",
        "Como retorno, recebemos um gráfico de dispersão onde a nuvem de pontos cartesianos parece desenhar melhor um padrão: conforme o g-0 aumenta, o valor de g-8 diminui. Aparentemente, a relação entre essas duas variáveis desenha uma curva com inclinação negativa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IE29BuQ9mA2h"
      },
      "source": [
        "sns.scatterplot(x='g_0', y = 'g_8', data=dados)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZNkBVhwmPO5"
      },
      "source": [
        "E, como parte do nosso trabalho é levantar hipóteses e confirmá-las (ou não), precisamos verificar se a nossa suspeita de que a relação entre as variáveis g-0 e g-8desenha uma curva com inclinação negativa.\n",
        "\n",
        "Para isso, vamos utilizar uma outra função do Seaborn, a lmplot. A lmplot vai desenhar no nosso gráfico de dispersão uma linha de tendência e, assim, poderemos confirmar o padrão daquele conjunto de dados.\n",
        "\n",
        "Os parâmetros a serem recebidos, são muito parecidos com aqueles usados no scatterplot. Então teremos\n",
        "\n",
        "sns.lmplot(data=base de dados, x='variavel para o eixo x', y='variavel para o eixo y', line_kws={'color': 'cor da linha de tendencia'})\n",
        "\n",
        "Utilizamos o parâmetro line_kws = {'color': 'red'} para criar um bom contraste entre os pontos do gráfico de dispersão e a linha de tendência.\n",
        "\n",
        "Observando o nosso gráfico, podemos concluir a nossa hipótese inicial, mas ele ainda não é suficiente para finalizarmos a nossa análise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnhsfAcHmR9-"
      },
      "source": [
        "sns.lmplot(data=dados, x='g_0', y='g_8', line_kws={'color': 'red'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxK_cOLUma8N"
      },
      "source": [
        "Para uma análise mais real e completa, é interessante que separemos ainda mais o nosso conjunto de dados. Isso porque, na imagem acima, apesar de termos uma linha de tendência para a relação entre os dados ```g-0``` e ```g-8```, não há filtros para a dosagem, o tratamento e o tempo. E, pesando em drug discorevy, é extremamente importante que façamos a separação desses conjuntos.\n",
        "\n",
        "Então, vamos acrescentar mais alguns parâmetros para executar a separação. Acrescentamos o parâmetro ```col = tramento``` para que sejam plotados gráficos de acordo com as categorias da variável em questão nas colunas (```com_droga``` e ```com_controle```) e também incluímos o parâmetro ```row = 'tempo'``` para que mais uma subdivisão seja feita e, as linhas apresentem novos gráficos com as diferentes categorias (```24```,```48``` e ```72```).\n",
        "\n",
        "Assim, podemos perceber as nuances de cada gráfico e o comportamento de determinado subconjunto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IU0nhcqEmiEk"
      },
      "source": [
        "sns.lmplot(data=dados, x='g_0', y='g_8', line_kws={'color': 'red'}, col='tratamento', row='tempo')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQRN3G7tmxpd"
      },
      "source": [
        "Outra medida para analisar como as variáveis estão associadas é a correlação. \n",
        "\n",
        "Para isso, vamos usar uma função já conhecida do Pandas, o ```loc``` e, vamos agregar o ```.corr```. O ```loc``` serve para definirmos o intervalo em que a correlação vai ser calculada. Aqui, estamos calculando a correlação entre todos os genes. \n",
        "\n",
        "Como retorno, temos uma tabela bem grande que correlaciona a variável e apresenta valores entre 1 e -1.\n",
        "Por exemplo, o primeiro valor numérico apresentado na primeira linha é o resultado da correlação entre a variável que está nesta linha e nesta coluna, no nosso caso, o ```g-0``` em ambas as extremidades. No primeiro valor numérico apresentado na segunda linha, temos a correlação entre ```g-1``` e ```g-0``` e assim por diante. \n",
        "\n",
        "Mas, como interpretar esses valores? Bom, temos a seguinte divisão:\n",
        "    \n",
        "    - Valores muito próximos de 1 ou -1: variáveis altamente correlacionadas\n",
        "    - Valores muito próximos de 0: variáveis pouco ou não correlacionadas\n",
        "\n",
        "E, o que diferencia se essa correlação será proporcional ou inversamente proporcional, será o sinal. Quer dizer:\n",
        "\n",
        "    - Valores muito próximos de 1: variáveis proporcionalmente correlacionadas\n",
        "    - Valores muito próximos de -1: variáveis correlacionadas inversamente proporcionais\n",
        "\n",
        "Agora que já sabemos como analisar essa tabela, podemos voltar para o nosso gráfico de dispersão construído com ```g-0``` e ```g-8`` e perceber que a nossa tabela confirma que ambas as variáveis estão correlacionadas e são inversamente proporcionais, visto que o valor apresentado na tabela é de -0,604212."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-9bL5IHmq4H"
      },
      "source": [
        "dados.loc[:,'g_0':'g_771'].corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-lPCeSAni5T"
      },
      "source": [
        "corr = dados.loc[:,'g_0':'g_50'].corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5sJRux-nKj5"
      },
      "source": [
        "O mapa de calor mostra uma escala de cores em sua lateral direita, a legenda e, para cada pontinho, podemos perceber a força da correlação sendo mostrada através de uma cor associada.\n",
        "\n",
        "Olhando para o nosso gráfico, percebemos que, em sua maioria, as expressões genicas não apresentam correlações tão altas entre si (podemos deduzir isso observando que o gráfico em grande parte é translúcido).\n",
        "\n",
        "É importante destacar que não podemos inferir causalidade a partir da correlação, como já descrevemos anteriormente no gráfico de dispersão. \n",
        "Exemplificando: vimos que ```g-0``` e ```g-8``` têm correlação inversamente proporcional entre si mas não podemos concluir que é o ```g-0``` que faz o ```g-8``` diminuir, ou seja, a causa.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emjHUbkMnQHj"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "# Generate a mask for the upper triangle\n",
        "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
        "\n",
        "# Set up the matplotlib figure\n",
        "f, ax = plt.subplots(figsize=(11, 9))\n",
        "\n",
        "# Generate a custom diverging colormap\n",
        "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
        "\n",
        "# Draw the heatmap with the mask and correct aspect ratio\n",
        "sns.heatmap(corr, mask=mask, cmap=cmap, center=0,\n",
        "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyWD4pCKn3Rh"
      },
      "source": [
        "Agora, vamos repetir o processo de construção do mapa de calor para a a viabilidade celular (```c```).\n",
        "\n",
        "Definimos uma nova variável ```corr_celular``` e ajustamos os parâmetros de acordo com os nossos ```cs```.\n",
        "\n",
        "Observando o gráfico de saída, podemos perceber uma grande diferença entre os dois mapas de calor que construímos. A escala deste novo gráfico é bem diferente da escala anterior, temos valores apenas entre 0,65 e 0,90, correlações altamente proporcionais."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mR7-EgRgnwxk"
      },
      "source": [
        "corr_celular = dados.loc[:,'c_0':'c_50'].corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uje2Dg7Jn8H5"
      },
      "source": [
        "\n",
        "# Generate a mask for the upper triangle\n",
        "mask = np.triu(np.ones_like(corr_celular, dtype=bool))\n",
        "\n",
        "# Set up the matplotlib figure\n",
        "f, ax = plt.subplots(figsize=(11, 9))\n",
        "\n",
        "# Generate a custom diverging colormap\n",
        "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
        "\n",
        "# Draw the heatmap with the mask and correct aspect ratio\n",
        "sns.heatmap(corr_celular, mask=mask, cmap=cmap, center=0,\n",
        "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwDlnAUppf6z"
      },
      "source": [
        "dados_resultados = pd.read_csv('https://github.com/alura-cursos/imersaodados3/blob/main/dados/dados_resultados.csv?raw=true')\n",
        "dados_resultados.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYegnBogqXd-"
      },
      "source": [
        "dados_resultados['acetylcholine_receptor_agonist'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WF3YdVCqaKp"
      },
      "source": [
        "dados_resultados.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Zx1pUQfqdV2"
      },
      "source": [
        "contagem_moa = dados_resultados.drop('id', axis=1).sum().sort_values(ascending=False)\n",
        "contagem_moa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o19MbrLQqibI"
      },
      "source": [
        "dados_resultados.drop('id', axis=1).sum(axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5EBVLaQqloS"
      },
      "source": [
        "dados_resultados.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hrz951CBqpkf"
      },
      "source": [
        "dados.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQLrS-4bqsLy"
      },
      "source": [
        "dados_resultados['n_moa'] = dados_resultados.drop('id', axis=1).sum(axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sRt9FKHqw3s"
      },
      "source": [
        "dados_resultados['n_moa'] != 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwB930ghq1FG"
      },
      "source": [
        "dados_resultados['ativo_moa'] = (dados_resultados['n_moa'] != 0)\n",
        "dados_resultados.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKBzB6BmrdWO"
      },
      "source": [
        " dados_combinados = pd.merge(dados, dados_resultados[['id','n_moa', 'ativo_moa']], on='id')\n",
        " dados_combinados.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dKsZ6__rfzr"
      },
      "source": [
        "dados_combinados.query('tratamento == \"com_controle\"' )['ativo_moa'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPp78qtirxVM"
      },
      "source": [
        "dados_combinados.query('tratamento == \"com_droga\"' )['ativo_moa'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3I3YzACr5Aj"
      },
      "source": [
        "composto_principal = dados_combinados['composto'].value_counts().index[:5]\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.boxplot(data = dados_combinados.query('composto in @composto_principal'), y= 'g_0', x='composto', hue='ativo_moa')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzZhdz1Qr8RT"
      },
      "source": [
        "dados_combinados.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zewNvMYs21U"
      },
      "source": [
        "dados_resultados.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2y0hhAztK3E"
      },
      "source": [
        "As etapas lógicas do nosso processo é:\n",
        "\n",
        "    Dado um composto -> temos a nossa assinatura celular (```g e c```) -> analisamos o(s) mecanismo(s) de ação ativados (MoA) \n",
        "\n",
        "Mas, a nossa pergunta a ser respondida é, **\"Dado um composto e uma assinatura celular, houve algum MoA ativado?\"** Então, as etapas lógicas passam a ser:\n",
        "\n",
        "    Composto -> assinatura celular -> MoA ativado?\n",
        "\n",
        "E como nosso modelo vai aprender a partir da nosa base de dados?\n",
        "\n",
        "    Composto 1 -> Assinatura A -> MoA = 1\n",
        "    Composto 2 -> Assinatura B -> MoA = 0\n",
        "    Composto 3 -> Assinatura C -> MoA = 1\n",
        "    ...\n",
        "    Composto N -> Assinatura N -> MoA = 0\n",
        "\n",
        "Ou seja, toda a nossa base de dados ```dados_combinados``` será a fonte de aprendizado do nosso modelo. Onde, cada experimento (linha) representa um exemplo (assinatura) já que temos a reunião de todas as informações necessárias para criar a nossa classificação binária e, terá como variável resposta, também chamada de target, a coluna ```ativo_moa```, uma variável binária (0, 1).\n",
        "\n",
        "E, por fim, o nosso modelo deverá ser capaz de resolver o seguinte problema:\n",
        "  \n",
        "    Composto candidato -> Assinatura X -> MoA = 1 OU MoA = 0?\n",
        "\n",
        "Existem diversas técnicas de ML que são capazes de solucionar o nosso problema mas aqui, vamos usar a **Regressão Logística** e, essa técnica já está implementada em uma biblioteca bastante usada e bem importante para ML no Python, o [Scikit-Learn](https://scikit-learn.org/stable/).\n",
        "\n",
        "Sugerimos que você leia essa documentação e se familiarize com esta biblioteca, ela será muito importante na sua trajetória como Cientista de Dados. E, clicando em \"Classification\" na página inicial, encontramos, no primeiro capítulo, chamado \"Linear Models\", o nosso subtítulo de interesse: [**\"1.1.11 Logistic Regression\"**](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQOzs5LntcCN"
      },
      "source": [
        "Quando implementamos um modelo de classificação, precisamos separar a nossa base de dados em base de treino e base de teste. A base de treino, vai ser onde o nosso modelo vai aprender e, a base de teste serve para a verificação do aprendizado do modelo, ou seja, poderemos entender se, de fato, as previsões do nosso modelo estão de acordo com o esperado. \n",
        "\n",
        "Não podemos treinar e testar o modelo com o mesmo conjunto de dados porque, seria muito mais fácil dele prever corretamente. A base de dados de teste, funciona como um novo conjunto onde poderemos medir o quanto o nosso modelo está acertando, dado que já temos a variável resposta real.\n",
        "\n",
        "Para fazer esta divisão, usamos uma função do Scikit-Learn chamada ```train_teste_split``` (como já aprendemos, para usar uma biblioteca ou função, precisamos, primeiramente, fazer a importação padrão e, neste caso, usaremos ```from sklearn.model_selection import train_test_split```).\n",
        "\n",
        "Para fazer a divisão da base de dados, é necessário definir qual será o nosso ```x``` e o nosso ```y```. Um modelo matemático, define um ```y``` em função de um ```x```, ou seja, ```f(x) = y```. Neste projeto, o nosso ```y``` será o target, ```ativo_moa``` e, ele será definido a partir de uma assinatura (conjunto composto por ```g``` + ```c``` ou , expressão gênica + viabilidade celular).\n",
        "\n",
        "Assim, teremos: \n",
        "\n",
        "    x = dados_combinados.select_dtypes('float64')  ->  toda a base de dados que tem os valores com o formato, ```float64```, no nosso caso, todas as variáveis ```g``` e ```c```\n",
        "\n",
        "    y = dados_combinados['ativo_moa']  ->  apenas a coluna target, ou seja, ```ativo_moa```\n",
        "\n",
        "Para o ```train_test_split``` definiremos:\n",
        "    \n",
        "    x_treino, x_teste, y_treino, y_teste\n",
        "\n",
        "E a função receberá como parâmetro:\n",
        "\n",
        "    train_test_split(x, y, test_size = 0.2)\n",
        "\n",
        "Onde, \n",
        "\n",
        "    x -> base de dados definida como x, no nosso caso, todas as variáveis ```g``` e ```c```\n",
        "\n",
        "    y -> variável resposta, no nosso caso, ```ativo_moa```\n",
        "\n",
        "    teste_size = 0.2 -> tamanho que definimos para a base de teste\n",
        "\n",
        "A proporção entre treino e teste, varia de acordo com o volume de dados que temos. Mas, usualmente, encontramos proporções 30/70, 25/75 ou 20/80. Aqui, definimos como 0,2 ou 20%, isso significa que a base de treino será composta pelos 80% restante.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lng_hfLhs2zj"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x = dados_combinados.select_dtypes('float64')\n",
        "y = dados_combinados['ativo_moa']\n",
        "\n",
        "x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, test_size = 0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eV5VxDcltlAD"
      },
      "source": [
        "Agora, podemos fazer a nossa primeira regressão logística.\n",
        "\n",
        "O primeiro passo, é definir o nosso ```x```, ```y``` e o ```x_treino, x_teste, y_treino, y_teste``` do ```train_test_split```.\n",
        "\n",
        "Após isso, definimos um nome para o nosso modelo (```modelo_rlogistica```) e declaramos a função ```LogisticRegression()```. Acrescentamos um parâmetro ```max_iter = 1000``` no modelo para que ele seja capaz de convergir para um resultado e assim, não recebemos nenhum warning no resultado.\n",
        "\n",
        "Em seguida, ajustamos o modelo com o ```.fit(x_treino, y_treino)``` (lembrando que os argumentos desta função são ```x``` e ```y``` e, usamos ```x_treino``` e ```y_treino``` porque será através dessas bases que o algoritmo aprenderá).\n",
        "\n",
        "E, por fim, usamos a função ```.score(x_teste, y_teste)``` para verificar como o nosso modelo ajustado está se saindo nos dados de teste. O ```score()```calcula a acurácia, ou seja, quantas predições o nosso modelo acertou na base de teste.\n",
        "\n",
        "Como resultado, temos o valor da acurácia: ~0,627. Então, concluímos que o nosso modelo está acertando ~62% das previsões (caso tivéssemos 100 experimentos, o modelo acertaria 62 casos e erraria 38 casos).\n",
        "\n",
        "Mas, como podemos estabelecer se este é um bom valor de acurácia ou não?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yuit4sYGtg97"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x = dados_combinados.select_dtypes('float64')\n",
        "y = dados_combinados['ativo_moa'] \n",
        "x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, test_size = 0.2, stratify=y, random_state=376)\n",
        "\n",
        "modelo_rlogistica = LogisticRegression(max_iter=1000)\n",
        "modelo_rlogistica.fit(x_treino, y_treino)\n",
        "modelo_rlogistica.score(x_teste, y_teste)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sde93ffuuGao"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# Isto está formatado como código\n",
        "```\n",
        "\n",
        "Para estabelecer se temos um bom valor de acurácia, precisamos de uma base comparativa, quer dizer, preciso dos resultados de um outro modelo para entender se estamos acertando mais ou menos casos.\n",
        "\n",
        "Para isso, o Scikit-Learn, já tem implementado alguns algoritmos que fazer modelos menos complexos e que podem ser usados como base comparativa. Neste caso, vamos usar o ```DummyClassifier```.\n",
        "\n",
        "O processo para ajustar este modelo é muito parecido com aquele que usamos para a regressão logística: dividimos a base em treino e teste, definimos um nome para esse modelo e o instanciamos, o ajustamos com os dados de treino e, ao final, verificamos a acurácia com o conjunto teste.\n",
        "\n",
        "Ao instanciarmos o ```DummyClassifier```, precisamos definir a estratégia que ele usará para fazer o ajuste do modelo. No nosso caso, definimos a estratégia será os dados mais frequentes, isso quer dizer que: dado o valor mais frequente da nossa variável resposta (```ativo_moa```), o modelo Dummy vai chutar que todos os eventos da base de dados assumem aquele valor no target. Assim, temos: ```DummyClassifier('most_frequent')```.\n",
        "\n",
        "Nesse momento, para calcular a acurácia, vamos usar outra estratégia, a função ```accuracy_score``` também do Scikit-Learn. Ela receberá como parâmetros a base teste da variável resposta (```y_teste```) e as previsões do modelo que, até o momento ainda não calculamos.\n",
        "Para calcular as previsões, usamos o ```.predict()``` da mesma biblioteca que, receberá como parâmetro a base ```x_teste```.\n",
        "Por fim, o cálculo da acurácia será: \n",
        "\n",
        "    previsao_dummy = modelo_dummy.predict(x_teste)\n",
        "    accuracy_score(y_teste, previsao_dummy)\n",
        "\n",
        "A acurácia do ```DummyClassifier```foi de ~60,7%, isso significa que nosso modelo ```LogisticRegression``` teve um desempenho um pouco melhor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-IS9o0-toOQ"
      },
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "modelo_dummy = DummyClassifier('most_frequent')\n",
        "modelo_dummy.fit(x_treino, y_treino)\n",
        "previsao_dummy = modelo_dummy.predict(x_teste)\n",
        "accuracy_score(y_teste, previsao_dummy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaOGDm7yuRZE"
      },
      "source": [
        "Podemos entender a acurácia do ```DummyClassifier``` se fizermos um ```value_counts``` normalizado e então verificamos que a proporção entre a classe 0 e a classe 1 é 60/30, ou seja, o valor mais frequente (estratégia usada no ```DummyClassifier```) representa 60% da base de dados.\n",
        "Isso quer dizer que, caso o modelo chutasse a mesma classe para todos os eventos da base de teste, teríamos um acerto de 60% dos casos. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkklejvKuNw4"
      },
      "source": [
        "dados_combinados['ativo_moa'].value_counts(normalize=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuH6I0oyumd6"
      },
      "source": [
        "Entretanto, toda vez que rodamos tanto a nossa regressão logística, quanto o nosso dummy classifier, recebemos como retorno um valor diferente de acurácia, apesar de em muitos casos, serem próximos.\n",
        "\n",
        "O ```train_test_split``` a base de dados em subconjuntos aleatórios de treino e teste. Isso significa que toda vez que você executá-lo, você obterá um resultado diferente.\n",
        "\n",
        "Por outro lado, se você declarar o parâmetro ```random_state = n```, poderá garantir que a saída de todas as execuções será igual, ou seja, sua divisão será sempre a mesma. Não importa qual número você escolherá para o ```random_state```, o importante é que toda vez que você usá-lo, sempre terá a mesma saída. \n",
        "\n",
        "Além do ```random_state```, existe mais um parâmetro bem importante que deve ser levado em consideração na divisão da nossa base de dados, o ```stratify```. \n",
        "\n",
        "Se repararmos na divisão da variável ```ativo_moa```, entre ```true``` e ```false```, percebemos que segue um balanceamento 60/40. E, é do nosso interesse que as bases de treino e teste sigam, além de uma divisão reprodutível (garantida com ```random_state```), a proporção original do conjunto de dados. Assim, atribuimos ```stratify = coluna```, onde ```coluna = nome da coluna que o stratify deve levar em consideração a proporção de classes```. No nosso caso, usamos ```stratify = y```, pois ```y``` é a nossa variável resposta e, é dela que o stratify deve considerar a proporção: 60/40.\n",
        "\n",
        "Esses parâmetros são úteis, porque garantimos que os resultados são reproduzíveis e compatíveis, independente do modelo (qual técnica, por exemplo, regressão logística, dummy classifier, árvore de decisão e etc) que vamos treinar e testar a partir desta divisão.\n",
        "\n",
        "Ou seja, ao final, nosso ```train_teste_split``` ficará:\n",
        "\n",
        "    x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, test_size = 0.2, stratify=y, random_state=376)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJ5vL7LtutY3"
      },
      "source": [
        "Nesse momento, temos interesse a explorar outras técnicas de modelagem para comparar os resultados obtidos e ver qual o melhor algoritmo que conseguimos produzir. \n",
        "\n",
        "Sendo assim, vamos testar uma nova técnica: a árvore de decisão.\n",
        "\n",
        "Novamente, a sequência lógica para ajustar esse novo modelo é muito parecida com que estávamos vendo até o momento: definimos as bases ```x``` e ```y```, fazemos o ```train_test_split```, declaramos o novo modelo, ajustamos e verificamos a acurácia. \n",
        "\n",
        "Aqui, vamos usar o ```DecisionTreeClassifier```, também da biblioteca Scikit-Learn. O único parâmetro que vamos declarar para esta função será o ```max_depth = 3``` mas, vamos explorar seu significado a seguir. \n",
        "\n",
        "Como resultado, temos uma acurácia (calculada a partir da base de teste) de ~0,61% e, é um pouco menos do que a acurácia obtida com a regressão logística."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYKKoMYuujXD"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "x = dados_combinados.select_dtypes('float64')\n",
        "y = dados_combinados['ativo_moa'] \n",
        "x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, test_size = 0.2, stratify=y, random_state=376)\n",
        "\n",
        "modelo_arvore = DecisionTreeClassifier(max_depth = 3)\n",
        "modelo_arvore.fit(x_treino, y_treino)\n",
        "modelo_arvore.score(x_teste, y_teste)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TT8qC6-Wu5UP"
      },
      "source": [
        "Agora, vamos entender melhor como funciona uma árvore de decisão e o que significa o parâmetro ```max_depth = 3```. \n",
        "Plotamos uma imagem que representa o nosso modelo e, nesse momento, é importante que você não se apegue ao código que usamos para isso. O que realmente é relevante é entender o algoritmo!\n",
        "\n",
        "A figura é dividida em 4 níveis e, o primeiro nível (estamos considerando a orientação de cima para baixo), é composto por apenas um quadro que é chamado de **nó raíz** ou somente **raíz** e ele tem como regras, os melhores atributos que podem dividir a nossa base de dados em dois conjuntos distintos (lembrando que nosso objetivo é separar a nossa base de dados em **mecanismo de ação ativado ou não ativado**).\n",
        "\n",
        "Entre o primeiro e o segundo nível (e nos demais níveis), temos duas setas: uma para a direita e outra para a esquerda. Essas setas são chamadas de **ramos** e subdividem o nível acima em dois outros conjuntos que separam novamente os dados em **mecanismo de ação ativado ou não ativado**, a partir de uma decisão.\n",
        "\n",
        "O último nível da árvore (mais abaixo), apresenta n quadros que apresentam características que devem ser levadas em conta na hora da classificação e se dividem em ```class = ativado``` e ```class = não ativado```. Esse nível não apresenta mais ramificações e, esses quadros são chamados de **folhas**.\n",
        "\n",
        "Se reparmos, a nossa árvore tem 3 níveis de decisão a partir da raíz e é exatamente isso que o parâmetro ```max_depth```representa: a profundidade da árvore."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8DiFlO3u_V4"
      },
      "source": [
        "from sklearn import tree\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(15, 10), facecolor='k')\n",
        "tree.plot_tree(modelo_arvore,\n",
        "               ax=ax,\n",
        "               fontsize=10,\n",
        "               rounded=True,\n",
        "               filled=True,\n",
        "               feature_names=x_treino.columns,\n",
        "               class_names=['Não Ativado', 'Ativado'])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTugvdP_vdTE"
      },
      "source": [
        "Como vimos, o desempenho do nosso novo modelo com apenas 3 camadas de decisão não foi tão satisfatório assim. Por isso, vamos variar o ```max_depth``` dentro de um intervalo de valores (range) e comparar os resultados obtidos. \n",
        "\n",
        "O processo para obter os valores que queremos, é sempre o mesmo. Por isso, vamos criar um loop ou um laço de repetição (um loop, executa um bloco de código em repetição enquanto uma condição é atendida). \n",
        "\n",
        "Então, após fazermos a separação da base de dados em ```x``` e ```y``` e dividí-las no ```train_test_split```, vamos criar um ```for``` para que nosso modelo seja treinado e testado em repetição dentro de um range. Para isso, faremos:\n",
        "\n",
        "    teste=[]  ->  criando lista para armazenar os resultados da acurácia nos dados de teste \n",
        "    treino=[]  ->  criando lista para armazenar os resultados da acurácia nos dados de treino \n",
        "    for i in range(1,15):  ->  estabelecendo condição que deve ser atendida (i) e range de valor (range(1, 15))\n",
        "        modelo_arvore = DecisionTreeClassifier(max_depth = i)  ->  instanciando modelo que será treinado e definindo max_depth = i, ou seja, estamos variando a profundidade da nossa árvore\n",
        "        modelo_arvore.fit(x_treino, y_treino)  ->  ajustando o modelo a partir das bases de treino\n",
        "        teste.append(modelo_arvore.score(x_teste, y_teste))  ->  armazenando os resultados de acurácia de teste dos modelos produzidos na lista 'teste'\n",
        "        treino.append(modelo_arvore.score(x_treino, y_treino))  ->  armazenando os resultados de acurácia de treino dos modelos produzidos na lista 'treino'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4DLTGwCvAA0"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "x = dados_combinados.select_dtypes('float64')\n",
        "y = dados_combinados['ativo_moa'] \n",
        "x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, test_size = 0.2, stratify=y, random_state=376)\n",
        "\n",
        "teste=[]\n",
        "treino=[]\n",
        "for i in range(1,15):\n",
        "    modelo_arvore = DecisionTreeClassifier(max_depth = i)\n",
        "    modelo_arvore.fit(x_treino, y_treino)\n",
        "    teste.append(modelo_arvore.score(x_teste, y_teste))\n",
        "    treino.append(modelo_arvore.score(x_treino, y_treino))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQnKCfREvwrv"
      },
      "source": [
        "Quando chamamos as saídas do nosso ```for``` (```teste``` e ```treino```), podemos observar um comportamento um pouco estranho: enquanto nos dados de teste, o valor da nossa acurácia vai caindo, nos dados de treino, esse valor vai aumentando."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqZzMQ8uwCcf"
      },
      "source": [
        "teste"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "il1DFXCCv1wR"
      },
      "source": [
        "treino"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yempQPSYwLd8"
      },
      "source": [
        "Para investigar o que aconteceu, vamos plotar um gráfico para entender o comportamento combinado dessas listas.\n",
        "\n",
        "Usaremos o ```lineplot``` do Seaborn para construir essa visualização. \n",
        "Como parâmetros, teremos: \n",
        "\n",
        "    x = range(1, 15)   ->  intervalo que usamos no for\n",
        "    y = teste e y = treino  ->  listas criamos no for e será usada no eixo y do gráfico\n",
        "    label = 'teste' e label = 'teste'  ->  etiqueta para identificar as duas linhas que estarão no gráfico \n",
        "\n",
        "Observando o gráfico produzido, podemos perceber que, inicialmente, os valores de treino e teste são muito próximos mas, conforme vamos aumentando o range, o valor da acurácia para os dados de treino aumentam muito enquanto, esse mesmo valor para os dados de teste, vai caindo (as linhas vão se afastando).\n",
        "\n",
        "Isso significa que, conforme aumentamos a profundidade da nossa árvore de decisão, a classificação para os dados de treino ficam muito boas pois, ela consegue captar muito bem as características desses dados. Mas, em contrapartida, o modelo fica tão bom os dados de treino que, quando apresentamos um novo conjunto de dados (teste), ele não consegue generalizar tão bem e assim, temos uma acurácia em queda.\n",
        "\n",
        "Esse problema de um modelo com performance muito boa nos dados de treino mas performance em queda nos dados de teste, é muito conhecido na ciência de dados e chamamos de **overfitting**.\n",
        "\n",
        "Então, conseguimos perceber que, para melhorar o nosso modelo, não é suficiente somente aumentar a profundidade da árvore de decisão e assim, precisamos traçar uma outra etratégia para melhorar a performance do nosso modelo.\n",
        "\n",
        "Nesse momento, vamos testar uma nova técnica de modelagem: o Random Forest. \n",
        "O que este modelo faz é criar várias árvores de decisões na qual ele considera amostras aleatórias do nosso conjunto total.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buikxOg4wwa7"
      },
      "source": [
        "sns.lineplot(x=range(1,15), y = teste, label='teste')\n",
        "sns.lineplot(x=range(1,15), y = treino, label='treino')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
